# This section includes all valid sr_research.eyelink.EyeTracker Device
# settings that can be specified in an iohub_config.yaml
# or in a Python dictionary form and passed to the quickStartHubServer
# method. Any device parameters not specified when the device class is
# created by the ioHub Process will be assigned the default value
# indicated here.
#
eyetracker.hw.sr_research.eyelink.EyeTracker:
    # name: The unique name to assign to the device instance created.
    #   The device is accessed from within the PsychoPy script 
    #   using the name's value; therefore it must be a valid Python
    #   variable name as well.
    #
    name: tracker

    # enable: Specifies if the device should be enabled by ioHub and monitored
    #   for events.
    #   True = Enable the device on the ioHub Server Process
    #   False = Disable the device on the ioHub Server Process. No events for
    #   this device will be reported by the ioHub Server.
    #    
    enable: True

    # save_events: *If* the ioHubDataStore is enabled for the experiment, then
    #   indicate if events for this device should be saved to the
    #   data_collection/keyboard event group in the hdf5 event file.
    #   True = Save events for this device to the ioDataStore.
    #   False = Do not save events for this device in the ioDataStore.
    #    
    save_events: True

    # stream_events: Indicate if events from this device should be made available
    #   during experiment runtime to the PsychoPy Process.
    #   True = Send events for this device to  the PsychoPy Process in real-time.
    #   False = Do *not* send events for this device to the PsychoPy Process in real-time.
    #    
    stream_events: True

    # auto_report_events: Indicate if events from this device should start being
    #   processed by the ioHub as soon as the device is loaded at the start of an experiment,
    #   or if events should only start to be monitored on the device when a call to the
    #   device's enableEventReporting method is made with a parameter value of True.
    #   True = Automatically start reporting events for this device when the experiment starts.
    #   False = Do not start reporting events for this device until enableEventReporting(True)
    #   is set for the device during experiment runtime.
    #
    auto_report_events: False

    # event_buffer_length: Specify the maximum number of events (for each
    #   event type the device produces) that can be stored by the ioHub Server
    #   before each new event results in the oldest event of the same type being
    #   discarded from the ioHub device event buffer.
    #
    event_buffer_length: 1024


    # device_timer: The EyeLink EyeTracker class uses the polling method to
    #   check for new events received from the EyeTracker device. 
    #   device_timer.interval specifies the sec.msec time between device polls.
    #   0.001 = 1 msec, so the device will be polled at a rate of 1000 Hz.   
    device_timer:
        interval: 0.001

    # monitor_event_types: The eyelink implementation of the common eye tracker 
    #   interface supports the following event types. If you would like to 
    #   exclude certain events from being saved or streamed during runtime, 
    #   remove them from the list below.
    #    
    monitor_event_types: [ MonocularEyeSampleEvent, BinocularEyeSampleEvent, FixationStartEvent, FixationEndEvent, SaccadeStartEvent, SaccadeEndEvent, BlinkStartEvent, BlinkEndEvent]
    
    calibration:
        # IMPORTANT: Note that while the gaze position data provided by ioHub
        # will be in the Display's coordinate system, the EyeLink internally
        # always uses a 0,0 pixel_width, pixel_height coordinate system
        # since internally calibration point positions are given as integers,
        # so if the actual display coordinate system was passed to EyeLink,
        # coordinate types like deg and norm would become very coarse in
        # possible target locations during calibration.
        
        # type: sr_research.eyelink.EyeTracker supports the following
        #   calibration types:
        #   THREE_POINTS, FIVE_POINTS, NINE_POINTS, THIRTEEN_POINTS
        type: NINE_POINTS

        # color_type: rgb, rgb255, named, hex, etc. Leave blank to use window's color space.
        color_type:

        # unit_type: norm, pix, height, deg, etc. Leave blank to use window's unit type.
        unit_type:

        # auto_pace: If True, the eye tracker will automatically progress from
        # one calibration point to the next. If False, a manual key or button press
        # is needed to progress to the next point.
        # 
        auto_pace: True


        # target_duration is the number of sec that a calibration point should
        # be displayed before moving onto the next point.
        target_duration: 1.5

        # target_delay specifies the time between target position presentations.
        target_delay: 0.75

        # **pacing_speed is deprecated. Please use 'target_delay' instead.**
        pacing_speed:
        
        # screen_background_color: Specifies the background color to
        #   set the calibration, validation, etc, screens to.
        screen_background_color: [128,128,128]

        # text_color specifies the foreground color of any text used during calibration.
        # If empty, text_color is calculated automatically based on screen_background_color.
        text_color:

        # target_type: Defines what form of calibration graphic should be used
        #   during calibration, validation, etc. Valid options are CIRCLE_TARGET, or CUSTOM.
        #   
        target_type: CIRCLE_TARGET

        # target_attributes: The associated target attributes must be supplied
        #   for the given target_type. If target type attribute sections are provided
        #   for target types other than the entry associated with the specified
        #   target_type value they will simple be ignored.
        #
        target_attributes:
            outer_diameter: 33.0
            inner_diameter: 6.0
            outer_stroke_width: 2.0
            outer_fill_color: [64,64,64]
            outer_line_color: [255,255,255]
            inner_stroke_width: 1.0
            inner_fill_color: [255,0,0]
            inner_line_color: [0,0,0]
            # outer_color and inner_color are deprecated
            outer_color:
            inner_color:

    # network_settings: Specify the Host computer IP address. Normally
    #   leaving it set to the default value is fine.
    #
    network_settings: 100.1.1.1

    # default_native_data_file_name: The sr_research.eyelink.EyeTracker supports
    #   saving a native eye tracker edf data file, the
    #   default_native_data_file_name value is used to set the default name for
    #   the file that will be saved, not including the .edf file type extension.
    #
    default_native_data_file_name: et_data

    # simulation_mode: Indicate if the eye tracker should provide mouse simulated 
    #   eye data instead of sending eye data based on a participants actual 
    #   eye movements. 
    #
    simulation_mode: False
    
    # enable_interface_without_connection: Specifying if the ioHub Device
    #   should be enabled without truly connecting to the underlying eye tracking
    #   hardware. If True, ioHub EyeTracker methods can be called but will
    #   provide no-op results and no eye data will be received by the ioHub Server.
    #   This mode can be useful for working on aspects of an eye tracking experiment when the
    #   actual eye tracking device is not available, for example stimulus presentation
    #   or other non eye tracker dependent experiment functionality.
    #    
    enable_interface_without_connection: False

    runtime_settings:
        # sampling_rate: Specify the desired sampling rate to use. Actual
        #   sample rates depend on the model being used. 
        #   Overall, possible rates are 250, 500, 1000, and 2000 Hz.
        #
        sampling_rate: 250

        # track_eyes: Which eye(s) should be tracked? 
        #   Supported Values:  LEFT_EYE, RIGHT_EYE, BINOCULAR
        #        
        track_eyes: RIGHT_EYE

        # sample_filtering: Defines the native eye tracker filtering level to be 
        #   applied to the sample event data before it is sent to the specified data stream.
        #   The sample filter section can contain multiple key : value entries if 
        #   the tracker implementation supports it, where each key is a sample stream type,
        #   and each value is the accociated filter level for that sample data stream.
        #   sr_research.eyelink.EyeTracker supported stream types are: 
        #       FILTER_ALL, FILTER_FILE, FILTER_ONLINE 
        #   Supported sr_research.eyelink.EyeTracker filter levels are:
        #       FILTER_LEVEL_OFF, FILTER_LEVEL_1, FILTER_LEVEL_2
        #   Note that if FILTER_ALL is specified, then other sample data stream values are
        #   ignored. If FILTER_ALL is not provided, ensure to specify the setting
        #   for both FILTER_FILE and FILTER_ONLINE as in this case if  either is not provided then
        #   the missing filter type will have filter level set to FILTER_OFF.
        #        
        sample_filtering:
            FILTER_FILE: FILTER_LEVEL_2
            FILTER_ONLINE: FILTER_LEVEL_OFF
        
        vog_settings:
            # pupil_measure_types: sr_research.eyelink.EyeTracker supports one
            #   pupil_measure_type parameter that is used for all eyes being tracked. 
            #   Valid options are:
            #       PUPIL_AREA, PUPIL_DIAMETER,
            #            
            pupil_measure_types: PUPIL_AREA

            # tracking_mode: Define whether the eye tracker should run in a pupil only
            #   mode or run in a pupil-cr mode. Valid options are: 
            #       PUPIL_CR_TRACKING, PUPIL_ONLY_TRACKING
            #   Depending on other settngs on the eyelink Host and the model and mode of
            #   eye tracker being used, this parameter may not be able to set the
            #   specified tracking mode. CHeck the mode listed on the camera setup
            #   screen of the Host PC after the experiment has started to confirm if
            #   the requested tracking mode was enabled. IMPORTANT: only use
            #   PUPIL_ONLY_TRACKING mode if using an EyeLink II system, or using
            #   the EyeLink 1000 is a head **fixed** setup. Any head movement
            #   when using PUPIL_ONLY_TRACKING will result in eye position signal drift.
            #            
            tracking_mode: PUPIL_CR_TRACKING

            # pupil_center_algorithm: The pupil_center_algorithm defines what 
            #   type of image processing approach should
            #   be used to determine the pupil center during image processing. 
            #   Valid possible values are for eyetracker.hw.sr_research.eyelink.EyeTracker are:
            #   ELLIPSE_FIT, or CENTROID_FIT
            #            
            pupil_center_algorithm: ELLIPSE_FIT

    # model_name: The model_name setting allows the definition of the eye tracker model being used.
    #   For the eyelink implementation, valid values are:
    #       'EYELINK 1000 DESKTOP', 'EYELINK 1000 TOWER', 'EYELINK 1000 REMOTE', 
    #       'EYELINK 1000 LONG RANGE'
    model_name: EYELINK 1000 DESKTOP

    # manufacturer_name: Used by Builder as the displayed name in the eye tracker selection dropdown.
    #
    manufacturer_name: SR Research Ltd

    # device_number: The device number to assign to the Analog Input device. 
    #   device_number is not used by this device type.
    #
    device_number: 0
