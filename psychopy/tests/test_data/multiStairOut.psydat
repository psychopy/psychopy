(ipsychopy.data
MultiStairHandler
p1
(dp2
S'_nextIntensity'
p3
F504765875.58415622
sS'totalTrials'
p4
I93
sS'thisPassRemaining'
p5
(lp6
sS'type'
p7
S'simple'
p8
sS'runningStaircases'
p9
(lp10
sS'currentStaircase'
p11
(ipsychopy.data
StairHandler
p12
(dp13
S'origin'
p14
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2011 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import misc, gui, log\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom matplotlib import mlab#used for importing csv files\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect#so that Handlers can find the script that called them\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a#                print 'TrialType has no attribute (or key) \u005c'%s\u005c'' %(name)\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a        \u000aclass TrialHandler:\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to .next() will fetch the next object given to this\u000a    handler, according to the method specified and will raise a \u000a    StopIteration error if trials have finished\u000a    \u000a    See demo_trialHandler.py\u000a    """\u000a    def __init__(self,\u000a                 trialList, \u000a                 nReps, \u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None):\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a            \u000a            """\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = nReps\u000a        self.nTotal = nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0		#records which repetition or pass we are on\u000a        self.thisTrialN = -1	#records which trial number within this repetition\u000a        self.thisIndex = 0		#the index of the current trial in the original matrix\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None: \u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a        \u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            self.originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a            log.debug("Using %s as origin file" %self.originPath)\u000a        else: self.originPath = originPath\u000a        self.origin = open(self.originPath).read().decode('utf8')\u000a        \u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self): \u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a        \u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a        \u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a                \u000a        strRepres+=')'\u000a        return strRepres\u000a    \u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically\u000a        when the TrialHandler is initialised so doesn't need an\u000a        explicit call from the user.\u000a        \u000a        sequence has form indices[stimN][repN]\u000a        """\u000a        \u000a        if self.method == 'random':            \u000a            sequenceIndices = []\u000a            # create indices for a single rep\u000a            indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a            seed=self.seed\u000a            for thisRep in range(int(self.nReps)):\u000a                thisRepSeq = misc.shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            return numpy.transpose(sequenceIndices)\u000a        \u000a        if self.method == 'sequential':\u000a            sequenceIndices = []\u000a            indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a            return sequenceIndices\u000a        \u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a        \u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a        \u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:        \u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a            \u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a    \u000a    def next(self):\u000a        """Advances to next trial and returns it.        \u000a        Updates attributes; thisTrial, thisTrialN and thisIndex        \u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a        \u000a            trials = TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff           \u000a                \u000a        or::\u000a        \u000a            trials = TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial                   \u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a            \u000a        if self.finished==True:\u000a            raise StopIteration\u000a        \u000a        #fetch the trial info\u000a        if self.method in ['random','sequential']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a        log.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a    def _parseDataOutput(self, dataOut):\u000a        \u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])	#will store data that has been analyzed\u000a        if type(dataOut)==str: dataout=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a        \u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        allDataTypes.remove('ran')\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n': \u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis \u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew        \u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a        dataOutInvalid=[]\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not self.data.has_key(dataType): \u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a            \u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1: thisAnal*=0 #prevent a divide-by-zero error\u000a                        else: thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:                \u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a        \u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a    def saveAsText(self,fileName, \u000a                   stimOut=[], \u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a        \u000a         :Parameters:\u000a         \u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.       \u000a            \u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings         \u000a            \u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found \u000a            \u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a            \u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a            \u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a            \u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        \u000a        dataOut, dataAnal, dataHead = self._parseDataOutput(dataOut=dataOut)\u000a        \u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file        \u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= file(fileName,writeFormat)\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a            \u000a        if not matrixOnly:\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                f.write('%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        \u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisType = type(self.trialList[stimN][heading])\u000a                if thisType==float: f.write('%.4f%s' %(self.trialList[stimN][heading],delim))\u000a                else: f.write('%s%s' %(self.trialList[stimN][heading],delim))\u000a                \u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): strVersion = str(tmpData.tolist())\u000a                else: strVersion = str(tmpData)\u000a                \u000a                if strVersion=='()': strVersion="--"#no data in masked array should show as "--"\u000a                \u000a                for brackets in ['[', ']','(',')']: #some objects may have these surrounding their string representation\u000a                    strVersion=string.replace(strVersion, brackets,"")\u000a                for newCell in [', ', '  ', ',']: #some objects may already have these as delimitters\u000a                    strVersion=string.replace(strVersion, newCell,delim)\u000a                #remove any multiple delimitters\u000a                while string.find(strVersion, delim+delim)>(-1):\u000a                    strVersion=string.replace(strVersion, delim+delim, delim)\u000a                #remove final delim\u000a                if strVersion[-1]==delim: \u000a                    strVersion=strVersion[:-1]\u000a                f.write('%s%s' %(strVersion, delim))\u000a            f.write('\u005cn')\u000a            \u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a            \u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a            \u000a        f.write("\u005cn")\u000a        if f != sys.stdout: \u000a            f.close()\u000a            log.info('saved data to %s' %f.name)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        f = open(fileName, "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        \u000a    def printAsText(self, stimOut=[], \u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: TrialHandler.nextTrial() will be deprecated\u000a        please use Trialhandler.next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            log.warning("""DEPRECATION WARNING: TrialHandler.nextTrial() will be deprecated\u000a        please use Trialhandler.next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False     \u000a        return self.next()\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a    \u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[], \u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,                    \u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have \u000a        one file for each participant and then multiple sheets for repeated sessions etc. \u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a        \u000a            sheetName: string\u000a                the name of the worksheet within the file \u000a                \u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided  \u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler \u000a                and give here the names of strings specifying entries in that dictionary         \u000a            \u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including \u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction \u000a                times across the trials assuming that `rt` values have been stored. \u000a                The default values will output the raw, mean and std of all datatypes found \u000a            \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a            \u000a        \u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a            \u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl: \u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a        dataOut, dataAnal, dataHead = self._parseDataOutput(dataOut=dataOut)\u000a        \u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a        \u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName): \u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                log.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a        \u000a        ew = ExcelWriter(workbook = wb)\u000a        \u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the header line\u000a        if not matrixOnly:\u000a            #write a header line\u000a            for colN, heading in enumerate(stimOut+dataHead):\u000a                if heading=='ran_sum': heading ='n'\u000a                ws.cell(_getExcelCellName(col=colN,row=0)).value=unicode(heading)\u000a                \u000a        #loop through lines (trialTypes), writing data\u000a        for stimN in range(len(self.trialList)):\u000a            #first the params for this trialType (from self.trialList)\u000a            for colN, heading in enumerate(stimOut):\u000a                ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(self.trialList[stimN][heading])\u000a            colN = len(stimOut)\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                datType = type(tmpData)\u000a                if tmpData is None:#just go to next column\u000a                    colN+=1\u000a                    continue\u000a                elif not hasattr(tmpData,'__iter__') or \u005c\u000a                    (hasattr(tmpData,'shape') and tmpData.shape==()):\u000a                    try: \u000a                        ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = float(tmpData)#if it can conver to a number (from numpy) then do it\u000a                    except:#some thi\u000a                        ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(tmpData)#else treat as unicode\u000a                    colN+=1                    \u000a                else:\u000a                    for entry in tmpData:\u000a                        try: \u000a                            ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = float(entry)\u000a                        except:#some thi\u000a                            ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(entry)\u000a                        colN+=1\u000a        \u000a        #add self.extraInfo\u000a        rowN = len(self.trialList)+2\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(0,rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(0,rowN)).value = unicode(key)+':'\u000a                ws.cell(_getExcelCellName(1,rowN)).value = (val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a\u000a\u000adef importTrialList(fileName, returnFieldNames=False):\u000a        """Imports a list of TrialTypes from an Excel (.xlsx) or comma-separated-value file. \u000a        \u000a        If `fileName` ends .csv then import as a comma-separated-value file will be used. \u000a        All other filenames will be treated as Excel 2007 (xlsx) files. Sorry no \u000a        support for older versions of Excel file are planned.\u000a        \u000a        The file should contain one row per type of trial needed and one column \u000a        for each parameter that defines the trial type. The first row should give\u000a        parameter names, which should;\u000a            \u000a            - be unique\u000a            - begin with a letter (upper or lower case)\u000a            - contain no spaces or other punctuation (underscores are permitted)\u000a        \u000a        """\u000a        if fileName in ['None','none',None]:\u000a            return []\u000a        elif not os.path.isfile(fileName):\u000a            raise ImportError, 'TrialTypes file not found: %s' %os.path.abspath(fileName)\u000a        \u000a        if fileName.endswith('.csv'):\u000a            #use csv import library to fetch the fieldNames\u000a            f = open(fileName,'rU')#the U converts lineendings to os.linesep\u000a            #lines = f.read().split(os.linesep)#csv module is temperamental with line endings\u000a            reader = csv.reader(f)#.split(os.linesep))\u000a            fieldNames = reader.next()\u000a            #use matplotlib to import data and intelligently check for data types\u000a            #all data in one column will be given a single type (e.g. if one cell is string, all will be set to string)\u000a            trialsArr = mlab.csv2rec(f)\u000a            f.close()\u000a            #convert the record array into a list of dicts\u000a            trialList = []\u000a            for trialN, trialType in enumerate(trialsArr):\u000a                thisTrial ={}\u000a                for fieldN, fieldName in enumerate(fieldNames):\u000a                    OK, msg = isValidVariableName(fieldName)\u000a                    if not OK:\u000a                        #provide error message about incorrect header\u000a                        msg.replace('Variables','Parameters (column headers)') #tailor message to this usage\u000a                        raise ImportError, '%s: %s' %(fieldName, msg)\u000a                    val = trialsArr[trialN][fieldN]\u000a                    #if it looks like a list, convert it\u000a                    if type(val)==numpy.string_ and val.startswith('[') and val.endswith(']'):\u000a                        exec('val=%s' %val)\u000a                    thisTrial[fieldName] = val\u000a                trialList.append(thisTrial)\u000a        else:\u000a            if not haveOpenpyxl: \u000a                raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a                return -1\u000a            wb = load_workbook(filename = fileName)\u000a            ws = wb.worksheets[0]\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a                       \u000a            #get headers\u000a            fieldNames = [] \u000a            for colN in range(nCols):\u000a                #get filedName and chack valid\u000a                fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a                OK, msg = isValidVariableName(fieldName)\u000a                if not OK:\u000a                    #provide error message about incorrect header\u000a                    msg.replace('Variables','Parameters (column headers)') #tailor message to this usage\u000a                    raise ImportError, '%s: %s' %(fieldName, msg)\u000a                else: \u000a                    fieldNames.append(fieldName)\u000a                \u000a            #loop trialTypes\u000a            trialList = []\u000a            for rowN in range(nRows)[1:]:#not first row\u000a                thisTrial={}\u000a                for colN in range(nCols):\u000a                    fieldName = fieldNames[colN]\u000a                    val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                    #if it looks like a list, convert it\u000a                    if type(val)==str and val.startswith('[') and val.endswith(']'):\u000a                        exec('val=%s' %val)\u000a                    thisTrial[fieldName] = val\u000a                trialList.append(thisTrial)\u000a            \u000a        if returnFieldNames:\u000a            return (trialList,fieldNames)\u000a        else:\u000a            return trialList\u000a        \u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a    \u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a    \u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a    \u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"], \u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial conbinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler:\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a    \u000a    See ``demo_trialHandler.py``\u000a        \u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse\u000a    \u000a    """\u000a    def __init__(self,\u000a                 startVal, \u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None):\u000a        """\u000a        :Parameters:\u000a            \u000a            startVal:\u000a                The initial value for the staircase.\u000a            \u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a    \u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a            \u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a                \u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a                \u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a                \u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using \u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or \u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods. \u000a                \u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in \u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)     \u000a            \u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a            \u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a                \u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a            \u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a                \u000a        """\u000a        \u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a            \u000a            """        \u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a        \u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True          \u000a            \u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either \u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        \u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            self.originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a            log.debug("Using %s as origin file" %self.originPath)\u000a        else: self.originPath = originPath\u000a        self.origin = open(self.originPath).read().decode('utf8')\u000a        \u000a    def __iter__(self):\u000a        return self\u000a        \u000a    def addData(self, result):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        \u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.data.append(result)\u000a        \u000a        #increment the counter of correct scores\u000a        if result==1: \u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a                \u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a                \u000a        self.calculateNextIntensity()\u000a                                        \u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a        \u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially \u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                self._intensityDec()\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                    self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                self._intensityInc()\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a            \u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            #make it harder\u000a            self._intensityDec()\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a            \u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!            \u000a            #make it easier\u000a            self._intensityInc()\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a                \u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a            \u000a        \u000a        #add reversal info \u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a            #and test if we're done\u000a            if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a                len(self.intensities)>=self.nTrials:\u000a                    self.finished=True\u000a            #new step size if necessary\u000a            if self._variableStep and self.finished==False:\u000a                if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                    #we've gone beyond the list of step sizes so just use the last one\u000a                    self.stepSizeCurrent = self.stepSizes[-1]\u000a                else:\u000a                    self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a                \u000a                \u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.   \u000a        \u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a            \u000a            staircase = StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a           \u000a        or::\u000a            \u000a            staircase = StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a            \u000a        """\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1        \u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            raise StopIteration\u000a        \u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None: \u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a        \u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None: \u000a            self._nextIntensity = self.minVal\u000a        \u000a        \u000a    def saveAsText(self,fileName, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension \u000a                `.dlm` will be added if not included.\u000a            \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        \u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        \u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a            \u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', '\u005ct')\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a        \u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', '\u005ct')\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a        \u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', '\u005ct')\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a        \u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', '\u005ct')\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a        \u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a            \u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a            \u000a        f.write("\u005cn")        \u000a        if f != sys.stdout: \u000a            f.close()\u000a            log.info('saved data to %s' %f.name)\u000a        \u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have \u000a        one file for each participant and then multiple sheets for repeated sessions etc. \u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity \u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a        \u000a            sheetName: string\u000a                the name of the worksheet within the file \u000a                \u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a                \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a                \u000a        """\u000a        \u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl: \u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a        \u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a        \u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName): \u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                log.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a        \u000a        ew = ExcelWriter(workbook = wb)\u000a        \u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a        \u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a        \u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        log.info('saved data to %s' %fileName)\u000a        \u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        log.info('saved data to %s' %f.name)\u000a        \u000a    def printAsText(self, stimOut=[], \u000a                    dataOut=('rt_mean','rt_std', 'acc_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout',  delim, matrixOnly)\u000a    \u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: StairHandler.nextTrial() will be deprecated\u000a        please use StairHandler.next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            log.warning("""DEPRECATION WARNING: StairHandler.nextTrial() will be deprecated\u000a        please use StairHandler.next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a        \u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm using python code from XXX.  f\u000a    Like StairHandler, it handles the selection of the next trial and report \u000a    current values etc. Calls to nextTrial() will fetch the next object given \u000a    to this handler, according to the method specified.\u000a\u000a    The staircase will terminate when *nTrials* or *XXX* has been exceeded.\u000a        \u000a    Measure threshold using a Weibull psychometric function. Currently, it is \u000a    not possible to use a different psychometric function.\u000a    \u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a    \u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a    \u000a    **Example**::\u000a    \u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # add response\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a        \u000a    """\u000a    def __init__(self,\u000a                 startVal, \u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a        \u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a        \u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function. \u000a        \u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a                \u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a            \u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e., \u000a                the midpoint of the table) yields pThreshold..\u000a            \u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a            \u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a            \u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a            \u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels \u000a                into decibels or log units and will move along the psychometric function with these values.\u000a            \u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a            \u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using \u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or \u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a            \u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a            \u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a            \u000a        """\u000a        \u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method, \u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a        \u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a                \u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a        \u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a        \u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a    \u000a    def addData(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        Also update the intensity\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        self.calculateNextIntensity()\u000a    \u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    \u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None: \u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a    \u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        return scaled_intensity\u000a    \u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        return intensity\u000a    \u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode())\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a    \u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a    \u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a    \u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest, \u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a    \u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a        \u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1        \u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            raise StopIteration\u000a    \u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler:\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or QUEST)\u000a        \u000a        \u000a        :params:\u000a        \u000a            stairType: 'simple' or 'quest'\u000a                Use a `~psychopy.data.StairHandler`_ or `~psychopy.data.QuestHandler`_\u000a                \u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than \u000a                that (so you can't have 3 repeats of the same staircase in a row \u000a                unless it's the only one still running)\u000a                \u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importTrialTypes`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a                \u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't \u000a                also met its minimal reversals. See `~psychopy.data.StairHandler`\u000a                \u000a        Example usage::\u000a        \u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = MultiStairHandler(conditions=conditions, trials=50)\u000a            \u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a                \u000a                #do something with thisIntensity and thisOri\u000a                \u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a                \u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a            \u000a        """\u000a        \u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            raise TypeError('conditions parameter to MultiStairHandler should be a list, not a %s' %type(conditions))\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            raise TypeError('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params: \u000a                raise ValueError('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params: \u000a                raise ValueError('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest': \u000a                raise ValueError("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            raise ValueError("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials, \u000a                'nUp':1, 'nDown':3, 'extraInfo':None, \u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None, \u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01, \u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None, \u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a        \u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter \u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals, \u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown, \u000a                    extraInfo=extraInfo, \u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'], \u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval, \u000a                    method=method, stepType=stepType, beta=beta, delta=delta, \u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo, \u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        \u000a        This can be handled with code such as::\u000a            \u000a            staircase = MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a           \u000a        or::\u000a            \u000a            staircase = MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a            \u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a                if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #return value\u000a        if self.finished==False:\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a    \u000a    def addData(self, result):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        \u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addData(result)\u000a        try:\u000a            self.currentStaircase.next()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        self.totalTrials+=1\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        log.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of \u000a        conditions during initialisation of the Handler.\u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity \u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a                \u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a                \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a                \u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label, \u000a                matrixOnly=False, appendFile=append)\u000a    def saveAsText(self,fileName, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data. \u000a        \u000a        For MultiStairHandler this will output one file for each staircase \u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler). \u000a        \u000a        :Parameters:\u000a        \u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension \u000a                `.dlm` will be added if not included.\u000a            \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim, \u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream \u000a        \u000a        :Parameters:\u000a        \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim, \u000a                matrixOnly=thisMatrixOnly)\u000a        \u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a    \u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a    \u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a    \u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a            \u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes: \u000a                self.addDataType(thisType)\u000a    \u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if type(names) != str:\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not self.has_key(thisType):\u000a            self.addDataType(thisType)\u000a        if position==None: \u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(self.trials.thisRepN)\u000a            \u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            log.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=misc.extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    \u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.fnName = fnName\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.params = guess\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        \u000a        if fnName[-4:] in ['2AFC', 'TAFC']:\u000a            self.expectedMin = 0.5\u000a        elif fnName[-2:] =='YN':\u000a            self.expectedMin=0.0\u000a        else:\u000a            self.expectedMin=expectedMin\u000a            \u000a        #do the calculations:\u000a        self._doFit()\u000a        \u000a    def _doFit(self):\u000a        #get some useful variables to help choose starting fit vals\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        if self.fnName in ['weibullTAFC','weibullYN']:\u000a            if self.params==None: guess=[xMean, xRange/5.0]\u000a            else: guess= numpy.asarray(self.params,'d')\u000a        elif self.fnName in ['cumNorm','erf']:\u000a            if self.params==None: guess=[xMean, xRange/5.0]#c50, xScale (slope)\u000a            else: guess= numpy.asarray(self.params,'d')\u000a        elif self.fnName in ['logisticTAFC','logistYN', 'logistic']:\u000a            if self.params==None: guess=[xMin, 5.0/xRange]#x0, xRate\u000a            else: guess= numpy.asarray(self.params,'d')  \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']: \u000a            if self.params==None: guess=[xMean, 2.0]#x50, expon\u000a            else: guess= numpy.asarray(self.params,'d')  \u000a        \u000a        self.params = optimize.fmin_cg(self._getErr, guess, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a        \u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a\u000a    def eval(self, xx=None, params=None):\u000a        if xx==None: xx=self.xx\u000a        if params==None: params=self.params\u000a        if self.fnName in ['weibullTAFC', 'weibull2AFC']:\u000a            alpha = params[0]; \u000a            if alpha<=0: alpha=0.001\u000a            beta = params[1]\u000a            xx = numpy.asarray(xx)\u000a            yy =  1.0 - 0.5*numpy.exp( - (xx/alpha)**beta ) \u000a        elif self.fnName == 'weibullYN':\u000a            alpha = params[0]; \u000a            if alpha<=0: alpha=0.001\u000a            beta = params[1]\u000a            xx = numpy.asarray(xx)\u000a            yy =  1.0 - numpy.exp( - (xx/alpha)**beta )         \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']:\u000a            c50 = params[0]\u000a            if c50<=0: c50=0.001\u000a            n = params[1]\u000a            if n<=0: n=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = rMax*(xx**n/(xx**n+c50**n))\u000a        elif self.fnName in [ 'erf', 'cumNorm']:\u000a            xShift = params[0]\u000a            xScale = params[1]\u000a            if xScale<=0: xScale=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = special.erf(xx*xScale - xShift)*0.5+0.5#numpy.special.erf() goes from -1:1\u000a        elif self.fnName in [ 'logisticYN', 'logistYN']:\u000a            x0 = params[0]\u000a            xRate = params[1]\u000a            if xRate<=0: xRate=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = 1.0/(1+(1.0/x0-1)*numpy.exp(-xRate*xx))\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        """Returns fitted xx for any given yy value(s).\u000a        \u000a        If params is specified this will override the current model params.\u000a        """\u000a        yy = numpy.asarray(yy)\u000a        if params==None: params=self.params\u000a        if self.fnName== 'weibullTAFC':\u000a            alpha = params[0]\u000a            beta = params[1]            \u000a            xx = alpha * (-numpy.log(2.0 * (1.0-yy))) **(1.0/beta)\u000a        elif self.fnName== 'weibullYN':\u000a            alpha = params[0]\u000a            beta = params[1]            \u000a            xx = alpha * (-numpy.log(1.0-yy))**(1.0/beta)\u000a        elif self.fnName in [ 'erf', 'cumNorm']:\u000a            xShift = params[0]\u000a            xScale = params[1]\u000a            xx = (special.erfinv(yy*2.0-1.0)+xShift)/xScale\u000a        elif self.fnName in [ 'logisticYN', 'logistYN']:\u000a            x0 = params[0]\u000a            xRate = params[1]\u000a            xx = -numpy.log( (1/yy-1)/(1/x0-1) )/xRate      \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']:\u000a            c50 = params[0]\u000a            n = params[1]\u000a            xx = c50/(1/yy-1)\u000a        return xx\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a    \u000a    You must overide the eval and inverse methods and a good idea to overide the _initialGuess\u000a    method aswell.\u000a    """\u000a    \u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #initialise parameters\u000a        if guess==None:\u000a            self.params = self._initialGuess()\u000a        else:\u000a            self.params = guess\u000a                \u000a        #do the calculations:\u000a        self._doFit()\u000a        \u000a    def _doFit(self):\u000a        #get some useful variables to help choose starting fit vals     \u000a#        self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    \u000a    def _initialGuess(self):\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        guess=[xMean, xRange/5.0]\u000a        return guess\u000a\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a\u000a    def eval(self, xx=None, params=None):\u000a        """Returns fitted yy for any given xx value(s).\u000a        Uses the original xx values (from which fit was calculated)\u000a        if none given.\u000a        \u000a        If params is specified this will override the current model params."""\u000a        yy=xx\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        """Returns fitted xx for any given yy value(s).\u000a        \u000a        If params is specified this will override the current model params.\u000a        """\u000a        #define the inverse for your function here\u000a        xx=yy\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a    \u000a    	y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a    \u000a    and with inverse::\u000a    \u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a        \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[alpha, beta]``)"""\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        alpha = params[0]; \u000a        if alpha<=0: alpha=0.001\u000a        beta = params[1]\u000a        xx = numpy.asarray(xx)\u000a        yy =  self.expectedMin + (1.0-self.expectedMin)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        alpha = params[0]\u000a        beta = params[1]            \u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-self.expectedMin))) **(1.0/beta)\u000a        return xx\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a    \u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a    \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a    \u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #initialise parameters\u000a        if guess==None:\u000a            self.params = self._initialGuess()\u000a        else:\u000a            self.params = guess\u000a                \u000a        #do the calculations:\u000a        self._doFit()\u000a    def _initialGuess(self):\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        guess=[xMean, 2.0, min(self.yy), max(self.yy)-min(self.yy)]\u000a        return guess \u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        c50 = params[0]\u000a        n = params[1]\u000a        rMin = params[2]\u000a        rMax = params[3]\u000a        #all params should be >0\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        \u000a        xx = numpy.asarray(xx)\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        #yy = (xx**n/(xx**n+c50**n))\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        yy=numpy.asarray(yy)\u000a        c50 = params[0]\u000a        n = params[1]\u000a        rMin = params[2]\u000a        rMax = params[3]\u000a        \u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        xx = (yScaled*c50**n/(1-yScaled))**(1/n)\u000a        return xx\u000a    \u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN) \u000a    of the form::\u000a    \u000a    	y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a    \u000a    and with inverse::\u000a    \u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a    \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        PSE = params[0]\u000a        JND = params[1]\u000a        chance = self.expectedMin\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        PSE = params[0]\u000a        JND = params[1]\u000a        chance = self.expectedMin\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-chance)/(yy-chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf) \u000a    of the form::\u000a    \u000a    	y = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)\u000a    \u000a    and with inverse::\u000a    \u000a        x = (erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        \u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with \u000a    fit.inverse(y) or retrieve the parameters from fit.params \u000a    (a list with [xShift, xScale])\u000a    """\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        xShift = params[0]\u000a        xScale = params[1]\u000a        chance = self.expectedMin        \u000a        if xScale<=0: xScale=0.001\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        xShift = params[0]\u000a        xScale = params[1]\u000a        chance = self.expectedMin\u000a        xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erf() goes from -1:1\u000a        return xx\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a    \u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a    \u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a    \u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a            \u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a    \u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure\u000a    \u000a    usage::\u000a    \u000a    	[intensity, meanCorrect, n] = functionFromStaircase(intensities, responses, bins)\u000a    \u000a    where:\u000a            intensities \u000a                are a list of intensities to be binned\u000a                \u000a            responses \u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a                \u000a            bins \u000a                can be an integer (giving that number of bins) or 'unique' (where each bin is made from ALL data for exactly one intensity value)\u000a\u000a            intensity \u000a                is the center of an intensity bin\u000a                \u000a            meanCorrect \u000a                is mean % correct in that bin\u000a                \u000a            n \u000a                is number of responses contributing to that mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a    \u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a    \u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            \u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a        \u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    Apr_19_1531 for 19th April 3.31pm.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    """\u000a    return time.strftime(format, time.localtime())\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a    \u000a    Usage:: \u000a        \u000a        OK, msg = isValidVariableName(name)\u000a        \u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    """\u000a    punctuation = " -[]()+*@!$%^&/\u005c{}~.,?'|:;"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name)==unicode:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a            \u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    for chr in punctuation:\u000a        if chr in name: return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a    \u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a    \u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    \u000a
p15
sS'nDown'
p16
I3
sS'reversalIntensities'
p17
(lp18
F5.0476587558415478
aF504765875.58415622
asS'stepSizes'
p19
I4
sS'nUp'
p20
I1
sS'startVal'
p21
F0.80000000000000004
sg3
F318485736.44279879
sS'_warnUseOfNext'
p22
I01
sS'method'
p23
S'2AFC'
p24
sS'maxVal'
p25
NsS'stepSizeCurrent'
p26
I4
sS'correctCounter'
p27
I0
sS'nReversals'
p28
NsS'minVal'
p29
NsS'finished'
p30
I01
sS'stepType'
p31
S'db'
p32
sS'data'
p33
(lp34
I0
aI0
aI0
aI0
aI1
aI0
aI0
aI0
aI0
aI1
aI0
aI0
aI0
aI0
aI1
aI0
aI0
aI0
aI0
aI0
aI1
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI0
aI1
aI0
aI0
aI1
aI0
aI0
aI1
aI0
aI1
aI1
aI1
asS'condition'
p35
(dp36
VstartVal
p37
F0.80000000000000004
sVlabel
p38
Vhigh
p39
sVstartValSd
p40
F0.29999999999999999
sVori
p41
I10
ssS'reversalPoints'
p42
(lp43
I3
aI53
asS'originPath'
p44
S'/Users/jwp/code/psychopy/git/psychopy/data.py'
p45
sS'extraInfo'
p46
NsS'currentDirection'
p47
S'down'
p48
sS'_variableStep'
p49
I00
sS'intensities'
p50
(lp51
F1.267914553968891
aF2.0095091452076645
aF3.184857364427979
aF5.0476587558415478
aF3.184857364427979
aF5.0476587558415478
aF8.0000000000000036
aF12.679145539688914
aF20.095091452076652
aF20.095091452076652
aF31.848573644279799
aF50.476587558415495
aF80.000000000000057
aF126.79145539688918
aF126.79145539688918
aF200.95091452076659
aF318.4857364427981
aF504.76587558415508
aF800.0000000000008
aF1267.9145539688921
aF1267.9145539688921
aF2009.5091452076663
aF3184.8573644279818
aF5047.6587558415522
aF8000.00000000001
aF12679.145539688925
aF20095.091452076671
aF31848.57364427983
aF50476.587558415544
aF80000.000000000146
aF126791.45539688932
aF200950.91452076679
aF318485.7364427984
aF504765.87558415561
aF800000.00000000163
aF1267914.5539688934
aF2009509.1452076684
aF3184857.3644279852
aF5047658.7558415579
aF8000000.0000000196
aF12679145.539688939
aF20095091.452076692
aF31848573.644279864
aF50476587.558415599
aF50476587.558415599
aF80000000.000000224
aF126791455.39688945
aF126791455.39688945
aF200950914.520767
aF318485736.44279879
aF318485736.44279879
aF504765875.58415622
aF504765875.58415622
aF504765875.58415622
asS'nTrials'
p52
I10
sS'thisTrialN'
p53
I53
sbsg30
I01
sS'staircases'
p54
(lp55
(ipsychopy.data
StairHandler
p56
(dp57
g14
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2011 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import misc, gui, log\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom matplotlib import mlab#used for importing csv files\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect#so that Handlers can find the script that called them\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a#                print 'TrialType has no attribute (or key) \u005c'%s\u005c'' %(name)\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a        \u000aclass TrialHandler:\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to .next() will fetch the next object given to this\u000a    handler, according to the method specified and will raise a \u000a    StopIteration error if trials have finished\u000a    \u000a    See demo_trialHandler.py\u000a    """\u000a    def __init__(self,\u000a                 trialList, \u000a                 nReps, \u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None):\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a            \u000a            """\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = nReps\u000a        self.nTotal = nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0		#records which repetition or pass we are on\u000a        self.thisTrialN = -1	#records which trial number within this repetition\u000a        self.thisIndex = 0		#the index of the current trial in the original matrix\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None: \u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a        \u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            self.originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a            log.debug("Using %s as origin file" %self.originPath)\u000a        else: self.originPath = originPath\u000a        self.origin = open(self.originPath).read().decode('utf8')\u000a        \u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self): \u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a        \u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a        \u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a                \u000a        strRepres+=')'\u000a        return strRepres\u000a    \u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically\u000a        when the TrialHandler is initialised so doesn't need an\u000a        explicit call from the user.\u000a        \u000a        sequence has form indices[stimN][repN]\u000a        """\u000a        \u000a        if self.method == 'random':            \u000a            sequenceIndices = []\u000a            # create indices for a single rep\u000a            indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a            seed=self.seed\u000a            for thisRep in range(int(self.nReps)):\u000a                thisRepSeq = misc.shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            return numpy.transpose(sequenceIndices)\u000a        \u000a        if self.method == 'sequential':\u000a            sequenceIndices = []\u000a            indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a            return sequenceIndices\u000a        \u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a        \u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a        \u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:        \u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a            \u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a    \u000a    def next(self):\u000a        """Advances to next trial and returns it.        \u000a        Updates attributes; thisTrial, thisTrialN and thisIndex        \u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a        \u000a            trials = TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff           \u000a                \u000a        or::\u000a        \u000a            trials = TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial                   \u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a            \u000a        if self.finished==True:\u000a            raise StopIteration\u000a        \u000a        #fetch the trial info\u000a        if self.method in ['random','sequential']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a        log.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a    def _parseDataOutput(self, dataOut):\u000a        \u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])	#will store data that has been analyzed\u000a        if type(dataOut)==str: dataout=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a        \u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        allDataTypes.remove('ran')\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n': \u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis \u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew        \u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a        dataOutInvalid=[]\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not self.data.has_key(dataType): \u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a            \u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1: thisAnal*=0 #prevent a divide-by-zero error\u000a                        else: thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:                \u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a        \u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a    def saveAsText(self,fileName, \u000a                   stimOut=[], \u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a        \u000a         :Parameters:\u000a         \u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.       \u000a            \u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings         \u000a            \u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found \u000a            \u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a            \u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a            \u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a            \u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        \u000a        dataOut, dataAnal, dataHead = self._parseDataOutput(dataOut=dataOut)\u000a        \u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file        \u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= file(fileName,writeFormat)\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a            \u000a        if not matrixOnly:\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                f.write('%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        \u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisType = type(self.trialList[stimN][heading])\u000a                if thisType==float: f.write('%.4f%s' %(self.trialList[stimN][heading],delim))\u000a                else: f.write('%s%s' %(self.trialList[stimN][heading],delim))\u000a                \u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): strVersion = str(tmpData.tolist())\u000a                else: strVersion = str(tmpData)\u000a                \u000a                if strVersion=='()': strVersion="--"#no data in masked array should show as "--"\u000a                \u000a                for brackets in ['[', ']','(',')']: #some objects may have these surrounding their string representation\u000a                    strVersion=string.replace(strVersion, brackets,"")\u000a                for newCell in [', ', '  ', ',']: #some objects may already have these as delimitters\u000a                    strVersion=string.replace(strVersion, newCell,delim)\u000a                #remove any multiple delimitters\u000a                while string.find(strVersion, delim+delim)>(-1):\u000a                    strVersion=string.replace(strVersion, delim+delim, delim)\u000a                #remove final delim\u000a                if strVersion[-1]==delim: \u000a                    strVersion=strVersion[:-1]\u000a                f.write('%s%s' %(strVersion, delim))\u000a            f.write('\u005cn')\u000a            \u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a            \u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a            \u000a        f.write("\u005cn")\u000a        if f != sys.stdout: \u000a            f.close()\u000a            log.info('saved data to %s' %f.name)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        f = open(fileName, "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        \u000a    def printAsText(self, stimOut=[], \u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: TrialHandler.nextTrial() will be deprecated\u000a        please use Trialhandler.next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            log.warning("""DEPRECATION WARNING: TrialHandler.nextTrial() will be deprecated\u000a        please use Trialhandler.next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False     \u000a        return self.next()\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a    \u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[], \u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,                    \u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have \u000a        one file for each participant and then multiple sheets for repeated sessions etc. \u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a        \u000a            sheetName: string\u000a                the name of the worksheet within the file \u000a                \u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided  \u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler \u000a                and give here the names of strings specifying entries in that dictionary         \u000a            \u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including \u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction \u000a                times across the trials assuming that `rt` values have been stored. \u000a                The default values will output the raw, mean and std of all datatypes found \u000a            \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a            \u000a        \u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a            \u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl: \u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a        dataOut, dataAnal, dataHead = self._parseDataOutput(dataOut=dataOut)\u000a        \u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a        \u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName): \u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                log.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a        \u000a        ew = ExcelWriter(workbook = wb)\u000a        \u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the header line\u000a        if not matrixOnly:\u000a            #write a header line\u000a            for colN, heading in enumerate(stimOut+dataHead):\u000a                if heading=='ran_sum': heading ='n'\u000a                ws.cell(_getExcelCellName(col=colN,row=0)).value=unicode(heading)\u000a                \u000a        #loop through lines (trialTypes), writing data\u000a        for stimN in range(len(self.trialList)):\u000a            #first the params for this trialType (from self.trialList)\u000a            for colN, heading in enumerate(stimOut):\u000a                ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(self.trialList[stimN][heading])\u000a            colN = len(stimOut)\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                datType = type(tmpData)\u000a                if tmpData is None:#just go to next column\u000a                    colN+=1\u000a                    continue\u000a                elif not hasattr(tmpData,'__iter__') or \u005c\u000a                    (hasattr(tmpData,'shape') and tmpData.shape==()):\u000a                    try: \u000a                        ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = float(tmpData)#if it can conver to a number (from numpy) then do it\u000a                    except:#some thi\u000a                        ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(tmpData)#else treat as unicode\u000a                    colN+=1                    \u000a                else:\u000a                    for entry in tmpData:\u000a                        try: \u000a                            ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = float(entry)\u000a                        except:#some thi\u000a                            ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(entry)\u000a                        colN+=1\u000a        \u000a        #add self.extraInfo\u000a        rowN = len(self.trialList)+2\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(0,rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(0,rowN)).value = unicode(key)+':'\u000a                ws.cell(_getExcelCellName(1,rowN)).value = (val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a\u000a\u000adef importTrialList(fileName, returnFieldNames=False):\u000a        """Imports a list of TrialTypes from an Excel (.xlsx) or comma-separated-value file. \u000a        \u000a        If `fileName` ends .csv then import as a comma-separated-value file will be used. \u000a        All other filenames will be treated as Excel 2007 (xlsx) files. Sorry no \u000a        support for older versions of Excel file are planned.\u000a        \u000a        The file should contain one row per type of trial needed and one column \u000a        for each parameter that defines the trial type. The first row should give\u000a        parameter names, which should;\u000a            \u000a            - be unique\u000a            - begin with a letter (upper or lower case)\u000a            - contain no spaces or other punctuation (underscores are permitted)\u000a        \u000a        """\u000a        if fileName in ['None','none',None]:\u000a            return []\u000a        elif not os.path.isfile(fileName):\u000a            raise ImportError, 'TrialTypes file not found: %s' %os.path.abspath(fileName)\u000a        \u000a        if fileName.endswith('.csv'):\u000a            #use csv import library to fetch the fieldNames\u000a            f = open(fileName,'rU')#the U converts lineendings to os.linesep\u000a            #lines = f.read().split(os.linesep)#csv module is temperamental with line endings\u000a            reader = csv.reader(f)#.split(os.linesep))\u000a            fieldNames = reader.next()\u000a            #use matplotlib to import data and intelligently check for data types\u000a            #all data in one column will be given a single type (e.g. if one cell is string, all will be set to string)\u000a            trialsArr = mlab.csv2rec(f)\u000a            f.close()\u000a            #convert the record array into a list of dicts\u000a            trialList = []\u000a            for trialN, trialType in enumerate(trialsArr):\u000a                thisTrial ={}\u000a                for fieldN, fieldName in enumerate(fieldNames):\u000a                    OK, msg = isValidVariableName(fieldName)\u000a                    if not OK:\u000a                        #provide error message about incorrect header\u000a                        msg.replace('Variables','Parameters (column headers)') #tailor message to this usage\u000a                        raise ImportError, '%s: %s' %(fieldName, msg)\u000a                    val = trialsArr[trialN][fieldN]\u000a                    #if it looks like a list, convert it\u000a                    if type(val)==numpy.string_ and val.startswith('[') and val.endswith(']'):\u000a                        exec('val=%s' %val)\u000a                    thisTrial[fieldName] = val\u000a                trialList.append(thisTrial)\u000a        else:\u000a            if not haveOpenpyxl: \u000a                raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a                return -1\u000a            wb = load_workbook(filename = fileName)\u000a            ws = wb.worksheets[0]\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a                       \u000a            #get headers\u000a            fieldNames = [] \u000a            for colN in range(nCols):\u000a                #get filedName and chack valid\u000a                fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a                OK, msg = isValidVariableName(fieldName)\u000a                if not OK:\u000a                    #provide error message about incorrect header\u000a                    msg.replace('Variables','Parameters (column headers)') #tailor message to this usage\u000a                    raise ImportError, '%s: %s' %(fieldName, msg)\u000a                else: \u000a                    fieldNames.append(fieldName)\u000a                \u000a            #loop trialTypes\u000a            trialList = []\u000a            for rowN in range(nRows)[1:]:#not first row\u000a                thisTrial={}\u000a                for colN in range(nCols):\u000a                    fieldName = fieldNames[colN]\u000a                    val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                    #if it looks like a list, convert it\u000a                    if type(val)==str and val.startswith('[') and val.endswith(']'):\u000a                        exec('val=%s' %val)\u000a                    thisTrial[fieldName] = val\u000a                trialList.append(thisTrial)\u000a            \u000a        if returnFieldNames:\u000a            return (trialList,fieldNames)\u000a        else:\u000a            return trialList\u000a        \u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a    \u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a    \u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a    \u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"], \u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial conbinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler:\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a    \u000a    See ``demo_trialHandler.py``\u000a        \u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse\u000a    \u000a    """\u000a    def __init__(self,\u000a                 startVal, \u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None):\u000a        """\u000a        :Parameters:\u000a            \u000a            startVal:\u000a                The initial value for the staircase.\u000a            \u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a    \u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a            \u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a                \u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a                \u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a                \u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using \u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or \u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods. \u000a                \u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in \u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)     \u000a            \u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a            \u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a                \u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a            \u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a                \u000a        """\u000a        \u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a            \u000a            """        \u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a        \u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True          \u000a            \u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either \u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        \u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            self.originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a            log.debug("Using %s as origin file" %self.originPath)\u000a        else: self.originPath = originPath\u000a        self.origin = open(self.originPath).read().decode('utf8')\u000a        \u000a    def __iter__(self):\u000a        return self\u000a        \u000a    def addData(self, result):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        \u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.data.append(result)\u000a        \u000a        #increment the counter of correct scores\u000a        if result==1: \u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a                \u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a                \u000a        self.calculateNextIntensity()\u000a                                        \u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a        \u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially \u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                self._intensityDec()\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                    self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                self._intensityInc()\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a            \u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            #make it harder\u000a            self._intensityDec()\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a            \u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!            \u000a            #make it easier\u000a            self._intensityInc()\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a                \u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a            \u000a        \u000a        #add reversal info \u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a            #and test if we're done\u000a            if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a                len(self.intensities)>=self.nTrials:\u000a                    self.finished=True\u000a            #new step size if necessary\u000a            if self._variableStep and self.finished==False:\u000a                if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                    #we've gone beyond the list of step sizes so just use the last one\u000a                    self.stepSizeCurrent = self.stepSizes[-1]\u000a                else:\u000a                    self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a                \u000a                \u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.   \u000a        \u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a            \u000a            staircase = StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a           \u000a        or::\u000a            \u000a            staircase = StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a            \u000a        """\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1        \u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            raise StopIteration\u000a        \u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None: \u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a        \u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None: \u000a            self._nextIntensity = self.minVal\u000a        \u000a        \u000a    def saveAsText(self,fileName, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension \u000a                `.dlm` will be added if not included.\u000a            \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        \u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        \u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a            \u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', '\u005ct')\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a        \u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', '\u005ct')\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a        \u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', '\u005ct')\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a        \u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', '\u005ct')\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a        \u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a            \u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a            \u000a        f.write("\u005cn")        \u000a        if f != sys.stdout: \u000a            f.close()\u000a            log.info('saved data to %s' %f.name)\u000a        \u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have \u000a        one file for each participant and then multiple sheets for repeated sessions etc. \u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity \u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a        \u000a            sheetName: string\u000a                the name of the worksheet within the file \u000a                \u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a                \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a                \u000a        """\u000a        \u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl: \u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a        \u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a        \u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName): \u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                log.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a        \u000a        ew = ExcelWriter(workbook = wb)\u000a        \u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a        \u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a        \u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        log.info('saved data to %s' %fileName)\u000a        \u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        log.info('saved data to %s' %f.name)\u000a        \u000a    def printAsText(self, stimOut=[], \u000a                    dataOut=('rt_mean','rt_std', 'acc_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout',  delim, matrixOnly)\u000a    \u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: StairHandler.nextTrial() will be deprecated\u000a        please use StairHandler.next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            log.warning("""DEPRECATION WARNING: StairHandler.nextTrial() will be deprecated\u000a        please use StairHandler.next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a        \u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm using python code from XXX.  f\u000a    Like StairHandler, it handles the selection of the next trial and report \u000a    current values etc. Calls to nextTrial() will fetch the next object given \u000a    to this handler, according to the method specified.\u000a\u000a    The staircase will terminate when *nTrials* or *XXX* has been exceeded.\u000a        \u000a    Measure threshold using a Weibull psychometric function. Currently, it is \u000a    not possible to use a different psychometric function.\u000a    \u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a    \u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a    \u000a    **Example**::\u000a    \u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # add response\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a        \u000a    """\u000a    def __init__(self,\u000a                 startVal, \u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a        \u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a        \u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function. \u000a        \u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a                \u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a            \u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e., \u000a                the midpoint of the table) yields pThreshold..\u000a            \u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a            \u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a            \u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a            \u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels \u000a                into decibels or log units and will move along the psychometric function with these values.\u000a            \u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a            \u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using \u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or \u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a            \u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a            \u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a            \u000a        """\u000a        \u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method, \u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a        \u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a                \u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a        \u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a        \u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a    \u000a    def addData(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        Also update the intensity\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        self.calculateNextIntensity()\u000a    \u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    \u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None: \u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a    \u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        return scaled_intensity\u000a    \u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        return intensity\u000a    \u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode())\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a    \u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a    \u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a    \u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest, \u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a    \u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a        \u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1        \u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            raise StopIteration\u000a    \u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler:\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or QUEST)\u000a        \u000a        \u000a        :params:\u000a        \u000a            stairType: 'simple' or 'quest'\u000a                Use a `~psychopy.data.StairHandler`_ or `~psychopy.data.QuestHandler`_\u000a                \u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than \u000a                that (so you can't have 3 repeats of the same staircase in a row \u000a                unless it's the only one still running)\u000a                \u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importTrialTypes`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a                \u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't \u000a                also met its minimal reversals. See `~psychopy.data.StairHandler`\u000a                \u000a        Example usage::\u000a        \u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = MultiStairHandler(conditions=conditions, trials=50)\u000a            \u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a                \u000a                #do something with thisIntensity and thisOri\u000a                \u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a                \u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a            \u000a        """\u000a        \u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            raise TypeError('conditions parameter to MultiStairHandler should be a list, not a %s' %type(conditions))\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            raise TypeError('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params: \u000a                raise ValueError('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params: \u000a                raise ValueError('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest': \u000a                raise ValueError("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            raise ValueError("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials, \u000a                'nUp':1, 'nDown':3, 'extraInfo':None, \u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None, \u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01, \u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None, \u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a        \u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter \u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals, \u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown, \u000a                    extraInfo=extraInfo, \u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'], \u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval, \u000a                    method=method, stepType=stepType, beta=beta, delta=delta, \u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo, \u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        \u000a        This can be handled with code such as::\u000a            \u000a            staircase = MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a           \u000a        or::\u000a            \u000a            staircase = MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a            \u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a                if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #return value\u000a        if self.finished==False:\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a    \u000a    def addData(self, result):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        \u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addData(result)\u000a        try:\u000a            self.currentStaircase.next()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        self.totalTrials+=1\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        log.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of \u000a        conditions during initialisation of the Handler.\u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity \u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a                \u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a                \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a                \u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label, \u000a                matrixOnly=False, appendFile=append)\u000a    def saveAsText(self,fileName, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data. \u000a        \u000a        For MultiStairHandler this will output one file for each staircase \u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler). \u000a        \u000a        :Parameters:\u000a        \u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension \u000a                `.dlm` will be added if not included.\u000a            \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim, \u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream \u000a        \u000a        :Parameters:\u000a        \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim, \u000a                matrixOnly=thisMatrixOnly)\u000a        \u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a    \u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a    \u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a    \u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a            \u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes: \u000a                self.addDataType(thisType)\u000a    \u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if type(names) != str:\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not self.has_key(thisType):\u000a            self.addDataType(thisType)\u000a        if position==None: \u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(self.trials.thisRepN)\u000a            \u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            log.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=misc.extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    \u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.fnName = fnName\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.params = guess\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        \u000a        if fnName[-4:] in ['2AFC', 'TAFC']:\u000a            self.expectedMin = 0.5\u000a        elif fnName[-2:] =='YN':\u000a            self.expectedMin=0.0\u000a        else:\u000a            self.expectedMin=expectedMin\u000a            \u000a        #do the calculations:\u000a        self._doFit()\u000a        \u000a    def _doFit(self):\u000a        #get some useful variables to help choose starting fit vals\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        if self.fnName in ['weibullTAFC','weibullYN']:\u000a            if self.params==None: guess=[xMean, xRange/5.0]\u000a            else: guess= numpy.asarray(self.params,'d')\u000a        elif self.fnName in ['cumNorm','erf']:\u000a            if self.params==None: guess=[xMean, xRange/5.0]#c50, xScale (slope)\u000a            else: guess= numpy.asarray(self.params,'d')\u000a        elif self.fnName in ['logisticTAFC','logistYN', 'logistic']:\u000a            if self.params==None: guess=[xMin, 5.0/xRange]#x0, xRate\u000a            else: guess= numpy.asarray(self.params,'d')  \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']: \u000a            if self.params==None: guess=[xMean, 2.0]#x50, expon\u000a            else: guess= numpy.asarray(self.params,'d')  \u000a        \u000a        self.params = optimize.fmin_cg(self._getErr, guess, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a        \u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a\u000a    def eval(self, xx=None, params=None):\u000a        if xx==None: xx=self.xx\u000a        if params==None: params=self.params\u000a        if self.fnName in ['weibullTAFC', 'weibull2AFC']:\u000a            alpha = params[0]; \u000a            if alpha<=0: alpha=0.001\u000a            beta = params[1]\u000a            xx = numpy.asarray(xx)\u000a            yy =  1.0 - 0.5*numpy.exp( - (xx/alpha)**beta ) \u000a        elif self.fnName == 'weibullYN':\u000a            alpha = params[0]; \u000a            if alpha<=0: alpha=0.001\u000a            beta = params[1]\u000a            xx = numpy.asarray(xx)\u000a            yy =  1.0 - numpy.exp( - (xx/alpha)**beta )         \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']:\u000a            c50 = params[0]\u000a            if c50<=0: c50=0.001\u000a            n = params[1]\u000a            if n<=0: n=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = rMax*(xx**n/(xx**n+c50**n))\u000a        elif self.fnName in [ 'erf', 'cumNorm']:\u000a            xShift = params[0]\u000a            xScale = params[1]\u000a            if xScale<=0: xScale=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = special.erf(xx*xScale - xShift)*0.5+0.5#numpy.special.erf() goes from -1:1\u000a        elif self.fnName in [ 'logisticYN', 'logistYN']:\u000a            x0 = params[0]\u000a            xRate = params[1]\u000a            if xRate<=0: xRate=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = 1.0/(1+(1.0/x0-1)*numpy.exp(-xRate*xx))\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        """Returns fitted xx for any given yy value(s).\u000a        \u000a        If params is specified this will override the current model params.\u000a        """\u000a        yy = numpy.asarray(yy)\u000a        if params==None: params=self.params\u000a        if self.fnName== 'weibullTAFC':\u000a            alpha = params[0]\u000a            beta = params[1]            \u000a            xx = alpha * (-numpy.log(2.0 * (1.0-yy))) **(1.0/beta)\u000a        elif self.fnName== 'weibullYN':\u000a            alpha = params[0]\u000a            beta = params[1]            \u000a            xx = alpha * (-numpy.log(1.0-yy))**(1.0/beta)\u000a        elif self.fnName in [ 'erf', 'cumNorm']:\u000a            xShift = params[0]\u000a            xScale = params[1]\u000a            xx = (special.erfinv(yy*2.0-1.0)+xShift)/xScale\u000a        elif self.fnName in [ 'logisticYN', 'logistYN']:\u000a            x0 = params[0]\u000a            xRate = params[1]\u000a            xx = -numpy.log( (1/yy-1)/(1/x0-1) )/xRate      \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']:\u000a            c50 = params[0]\u000a            n = params[1]\u000a            xx = c50/(1/yy-1)\u000a        return xx\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a    \u000a    You must overide the eval and inverse methods and a good idea to overide the _initialGuess\u000a    method aswell.\u000a    """\u000a    \u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #initialise parameters\u000a        if guess==None:\u000a            self.params = self._initialGuess()\u000a        else:\u000a            self.params = guess\u000a                \u000a        #do the calculations:\u000a        self._doFit()\u000a        \u000a    def _doFit(self):\u000a        #get some useful variables to help choose starting fit vals     \u000a#        self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    \u000a    def _initialGuess(self):\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        guess=[xMean, xRange/5.0]\u000a        return guess\u000a\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a\u000a    def eval(self, xx=None, params=None):\u000a        """Returns fitted yy for any given xx value(s).\u000a        Uses the original xx values (from which fit was calculated)\u000a        if none given.\u000a        \u000a        If params is specified this will override the current model params."""\u000a        yy=xx\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        """Returns fitted xx for any given yy value(s).\u000a        \u000a        If params is specified this will override the current model params.\u000a        """\u000a        #define the inverse for your function here\u000a        xx=yy\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a    \u000a    	y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a    \u000a    and with inverse::\u000a    \u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a        \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[alpha, beta]``)"""\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        alpha = params[0]; \u000a        if alpha<=0: alpha=0.001\u000a        beta = params[1]\u000a        xx = numpy.asarray(xx)\u000a        yy =  self.expectedMin + (1.0-self.expectedMin)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        alpha = params[0]\u000a        beta = params[1]            \u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-self.expectedMin))) **(1.0/beta)\u000a        return xx\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a    \u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a    \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a    \u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #initialise parameters\u000a        if guess==None:\u000a            self.params = self._initialGuess()\u000a        else:\u000a            self.params = guess\u000a                \u000a        #do the calculations:\u000a        self._doFit()\u000a    def _initialGuess(self):\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        guess=[xMean, 2.0, min(self.yy), max(self.yy)-min(self.yy)]\u000a        return guess \u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        c50 = params[0]\u000a        n = params[1]\u000a        rMin = params[2]\u000a        rMax = params[3]\u000a        #all params should be >0\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        \u000a        xx = numpy.asarray(xx)\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        #yy = (xx**n/(xx**n+c50**n))\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        yy=numpy.asarray(yy)\u000a        c50 = params[0]\u000a        n = params[1]\u000a        rMin = params[2]\u000a        rMax = params[3]\u000a        \u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        xx = (yScaled*c50**n/(1-yScaled))**(1/n)\u000a        return xx\u000a    \u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN) \u000a    of the form::\u000a    \u000a    	y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a    \u000a    and with inverse::\u000a    \u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a    \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        PSE = params[0]\u000a        JND = params[1]\u000a        chance = self.expectedMin\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        PSE = params[0]\u000a        JND = params[1]\u000a        chance = self.expectedMin\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-chance)/(yy-chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf) \u000a    of the form::\u000a    \u000a    	y = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)\u000a    \u000a    and with inverse::\u000a    \u000a        x = (erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        \u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with \u000a    fit.inverse(y) or retrieve the parameters from fit.params \u000a    (a list with [xShift, xScale])\u000a    """\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        xShift = params[0]\u000a        xScale = params[1]\u000a        chance = self.expectedMin        \u000a        if xScale<=0: xScale=0.001\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        xShift = params[0]\u000a        xScale = params[1]\u000a        chance = self.expectedMin\u000a        xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erf() goes from -1:1\u000a        return xx\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a    \u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a    \u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a    \u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a            \u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a    \u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure\u000a    \u000a    usage::\u000a    \u000a    	[intensity, meanCorrect, n] = functionFromStaircase(intensities, responses, bins)\u000a    \u000a    where:\u000a            intensities \u000a                are a list of intensities to be binned\u000a                \u000a            responses \u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a                \u000a            bins \u000a                can be an integer (giving that number of bins) or 'unique' (where each bin is made from ALL data for exactly one intensity value)\u000a\u000a            intensity \u000a                is the center of an intensity bin\u000a                \u000a            meanCorrect \u000a                is mean % correct in that bin\u000a                \u000a            n \u000a                is number of responses contributing to that mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a    \u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a    \u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            \u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a        \u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    Apr_19_1531 for 19th April 3.31pm.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    """\u000a    return time.strftime(format, time.localtime())\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a    \u000a    Usage:: \u000a        \u000a        OK, msg = isValidVariableName(name)\u000a        \u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    """\u000a    punctuation = " -[]()+*@!$%^&/\u005c{}~.,?'|:;"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name)==unicode:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a            \u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    for chr in punctuation:\u000a        if chr in name: return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a    \u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a    \u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    \u000a
p58
sg16
I3
sg17
(lp59
F0.31697863849222274
aF0.20000000000000001
aF0.12619146889603866
aF0.50237728630191625
asg19
I4
sg20
I1
sg21
F0.20000000000000001
sg3
F0.3169786384922228
sg22
I01
sg23
g24
sg25
Nsg26
I4
sg27
I0
sg28
Nsg29
Nsg30
I01
sg31
g32
sg33
(lp60
I0
aI1
aI1
aI1
aI1
aI1
aI1
aI0
aI1
aI0
aI1
aI1
aI0
aI1
aI1
aI1
asg35
(dp61
g37
F0.20000000000000001
sg38
Vlow
p62
sg40
F0.10000000000000001
sg41
I10
ssg42
(lp63
I0
aI3
aI6
aI14
asg44
g45
sg46
Nsg47
g48
sg49
I00
sg50
(lp64
F0.31697863849222274
aF0.20000000000000001
aF0.20000000000000001
aF0.20000000000000001
aF0.12619146889603866
aF0.12619146889603866
aF0.12619146889603866
aF0.20000000000000004
aF0.20000000000000004
aF0.3169786384922228
aF0.3169786384922228
aF0.3169786384922228
aF0.50237728630191625
aF0.50237728630191625
aF0.50237728630191625
asg52
I10
sg53
I14
sba(ipsychopy.data
StairHandler
p65
(dp66
g14
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2011 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import misc, gui, log\u000aimport psychopy\u000aimport cPickle, string, sys, platform, os, time, copy, csv\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom matplotlib import mlab#used for importing csv files\u000afrom contrib.quest import *    #used for QuestHandler\u000aimport inspect#so that Handlers can find the script that called them\u000a\u000atry:\u000a    import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept:\u000a    haveOpenpyxl=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a#                print 'TrialType has no attribute (or key) \u005c'%s\u005c'' %(name)\u000a                raise AttributeError, ('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a        \u000aclass TrialHandler:\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to .next() will fetch the next object given to this\u000a    handler, according to the method specified and will raise a \u000a    StopIteration error if trials have finished\u000a    \u000a    See demo_trialHandler.py\u000a    """\u000a    def __init__(self,\u000a                 trialList, \u000a                 nReps, \u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None):\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a            \u000a            """\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(trialList):\u000a            if type(entry)==dict:\u000a                trialList[n]=TrialType(entry)\u000a        self.nReps = nReps\u000a        self.nTotal = nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0		#records which repetition or pass we are on\u000a        self.thisTrialN = -1	#records which trial number within this repetition\u000a        self.thisIndex = 0		#the index of the current trial in the original matrix\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None: \u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a        \u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            self.originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a            log.debug("Using %s as origin file" %self.originPath)\u000a        else: self.originPath = originPath\u000a        self.origin = open(self.originPath).read().decode('utf8')\u000a        \u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self): \u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a        \u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a        \u000a        #print data first, then all others\u000a        try: data=self.data\u000a        except: data=None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a                \u000a        strRepres+=')'\u000a        return strRepres\u000a    \u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations\u000a        (for non-adaptive methods). This is called automatically\u000a        when the TrialHandler is initialised so doesn't need an\u000a        explicit call from the user.\u000a        \u000a        sequence has form indices[stimN][repN]\u000a        """\u000a        \u000a        if self.method == 'random':            \u000a            sequenceIndices = []\u000a            # create indices for a single rep\u000a            indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a            seed=self.seed\u000a            for thisRep in range(int(self.nReps)):\u000a                thisRepSeq = misc.shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            return numpy.transpose(sequenceIndices)\u000a        \u000a        if self.method == 'sequential':\u000a            sequenceIndices = []\u000a            indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a            return sequenceIndices\u000a        \u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a        \u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a        \u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:        \u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a            \u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a    \u000a    def next(self):\u000a        """Advances to next trial and returns it.        \u000a        Updates attributes; thisTrial, thisTrialN and thisIndex        \u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a        \u000a            trials = TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff           \u000a                \u000a        or::\u000a        \u000a            trials = TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial                   \u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a            \u000a        if self.finished==True:\u000a            raise StopIteration\u000a        \u000a        #fetch the trial info\u000a        if self.method in ['random','sequential']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a        log.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a    def _parseDataOutput(self, dataOut):\u000a        \u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])	#will store data that has been analyzed\u000a        if type(dataOut)==str: dataout=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list: dataOut = list(dataOut)\u000a        \u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        allDataTypes.remove('ran')\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut=='n': \u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis \u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if dataType=='all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew        \u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a        dataOutInvalid=[]\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType =string.rsplit(thisDataOut, '_', 1)\u000a            if not self.data.has_key(dataType): \u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a            \u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. his should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1: thisAnal*=0 #prevent a divide-by-zero error\u000a                        else: thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError, 'You can only use analyses from numpy'\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:                \u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a        \u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid: dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a    def saveAsText(self,fileName, \u000a                   stimOut=[], \u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                  ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a        \u000a         :Parameters:\u000a         \u000a            fileName:\u000a                will have .dlm appended (so you can double-click it to\u000a                open in excel) and can include path info.       \u000a            \u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings         \u000a            \u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found \u000a            \u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a            \u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a            \u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a            \u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        \u000a        dataOut, dataAnal, dataHead = self._parseDataOutput(dataOut=dataOut)\u000a        \u000a        #create the file or print to stdout\u000a        if appendFile: writeFormat='a'\u000a        else: writeFormat='w' #will overwrite a file        \u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv', '.CSV']:\u000a            f= file(fileName,writeFormat)\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a            \u000a        if not matrixOnly:\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum': heading ='n'\u000a                f.write('%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        \u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisType = type(self.trialList[stimN][heading])\u000a                if thisType==float: f.write('%.4f%s' %(self.trialList[stimN][heading],delim))\u000a                else: f.write('%s%s' %(self.trialList[stimN][heading],delim))\u000a                \u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): strVersion = str(tmpData.tolist())\u000a                else: strVersion = str(tmpData)\u000a                \u000a                if strVersion=='()': strVersion="--"#no data in masked array should show as "--"\u000a                \u000a                for brackets in ['[', ']','(',')']: #some objects may have these surrounding their string representation\u000a                    strVersion=string.replace(strVersion, brackets,"")\u000a                for newCell in [', ', '  ', ',']: #some objects may already have these as delimitters\u000a                    strVersion=string.replace(strVersion, newCell,delim)\u000a                #remove any multiple delimitters\u000a                while string.find(strVersion, delim+delim)>(-1):\u000a                    strVersion=string.replace(strVersion, delim+delim, delim)\u000a                #remove final delim\u000a                if strVersion[-1]==delim: \u000a                    strVersion=strVersion[:-1]\u000a                f.write('%s%s' %(strVersion, delim))\u000a            f.write('\u005cn')\u000a            \u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a            \u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a            \u000a        f.write("\u005cn")\u000a        if f != sys.stdout: \u000a            f.close()\u000a            log.info('saved data to %s' %f.name)\u000a\u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a        f = open(fileName, "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        \u000a    def printAsText(self, stimOut=[], \u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: TrialHandler.nextTrial() will be deprecated\u000a        please use Trialhandler.next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            log.warning("""DEPRECATION WARNING: TrialHandler.nextTrial() will be deprecated\u000a        please use Trialhandler.next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False     \u000a        return self.next()\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a    \u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=[], \u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,                    \u000a                    appendFile=True,\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have \u000a        one file for each participant and then multiple sheets for repeated sessions etc. \u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a        \u000a            sheetName: string\u000a                the name of the worksheet within the file \u000a                \u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided  \u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler \u000a                and give here the names of strings specifying entries in that dictionary         \u000a            \u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including \u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction \u000a                times across the trials assuming that `rt` values have been stored. \u000a                The default values will output the raw, mean and std of all datatypes found \u000a            \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a            \u000a        \u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            log.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a            \u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl: \u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a        dataOut, dataAnal, dataHead = self._parseDataOutput(dataOut=dataOut)\u000a        \u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a        \u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName): \u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                log.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a        \u000a        ew = ExcelWriter(workbook = wb)\u000a        \u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the header line\u000a        if not matrixOnly:\u000a            #write a header line\u000a            for colN, heading in enumerate(stimOut+dataHead):\u000a                if heading=='ran_sum': heading ='n'\u000a                ws.cell(_getExcelCellName(col=colN,row=0)).value=unicode(heading)\u000a                \u000a        #loop through lines (trialTypes), writing data\u000a        for stimN in range(len(self.trialList)):\u000a            #first the params for this trialType (from self.trialList)\u000a            for colN, heading in enumerate(stimOut):\u000a                ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(self.trialList[stimN][heading])\u000a            colN = len(stimOut)\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                datType = type(tmpData)\u000a                if tmpData is None:#just go to next column\u000a                    colN+=1\u000a                    continue\u000a                elif not hasattr(tmpData,'__iter__') or \u005c\u000a                    (hasattr(tmpData,'shape') and tmpData.shape==()):\u000a                    try: \u000a                        ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = float(tmpData)#if it can conver to a number (from numpy) then do it\u000a                    except:#some thi\u000a                        ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(tmpData)#else treat as unicode\u000a                    colN+=1                    \u000a                else:\u000a                    for entry in tmpData:\u000a                        try: \u000a                            ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = float(entry)\u000a                        except:#some thi\u000a                            ws.cell(_getExcelCellName(col=colN,row=stimN+1)).value = unicode(entry)\u000a                        colN+=1\u000a        \u000a        #add self.extraInfo\u000a        rowN = len(self.trialList)+2\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(0,rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(0,rowN)).value = unicode(key)+':'\u000a                ws.cell(_getExcelCellName(1,rowN)).value = (val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a\u000a\u000adef importTrialList(fileName, returnFieldNames=False):\u000a        """Imports a list of TrialTypes from an Excel (.xlsx) or comma-separated-value file. \u000a        \u000a        If `fileName` ends .csv then import as a comma-separated-value file will be used. \u000a        All other filenames will be treated as Excel 2007 (xlsx) files. Sorry no \u000a        support for older versions of Excel file are planned.\u000a        \u000a        The file should contain one row per type of trial needed and one column \u000a        for each parameter that defines the trial type. The first row should give\u000a        parameter names, which should;\u000a            \u000a            - be unique\u000a            - begin with a letter (upper or lower case)\u000a            - contain no spaces or other punctuation (underscores are permitted)\u000a        \u000a        """\u000a        if fileName in ['None','none',None]:\u000a            return []\u000a        elif not os.path.isfile(fileName):\u000a            raise ImportError, 'TrialTypes file not found: %s' %os.path.abspath(fileName)\u000a        \u000a        if fileName.endswith('.csv'):\u000a            #use csv import library to fetch the fieldNames\u000a            f = open(fileName,'rU')#the U converts lineendings to os.linesep\u000a            #lines = f.read().split(os.linesep)#csv module is temperamental with line endings\u000a            reader = csv.reader(f)#.split(os.linesep))\u000a            fieldNames = reader.next()\u000a            #use matplotlib to import data and intelligently check for data types\u000a            #all data in one column will be given a single type (e.g. if one cell is string, all will be set to string)\u000a            trialsArr = mlab.csv2rec(f)\u000a            f.close()\u000a            #convert the record array into a list of dicts\u000a            trialList = []\u000a            for trialN, trialType in enumerate(trialsArr):\u000a                thisTrial ={}\u000a                for fieldN, fieldName in enumerate(fieldNames):\u000a                    OK, msg = isValidVariableName(fieldName)\u000a                    if not OK:\u000a                        #provide error message about incorrect header\u000a                        msg.replace('Variables','Parameters (column headers)') #tailor message to this usage\u000a                        raise ImportError, '%s: %s' %(fieldName, msg)\u000a                    val = trialsArr[trialN][fieldN]\u000a                    #if it looks like a list, convert it\u000a                    if type(val)==numpy.string_ and val.startswith('[') and val.endswith(']'):\u000a                        exec('val=%s' %val)\u000a                    thisTrial[fieldName] = val\u000a                trialList.append(thisTrial)\u000a        else:\u000a            if not haveOpenpyxl: \u000a                raise ImportError, 'openpyxl is required for loading excel format files, but it was not found.'\u000a                return -1\u000a            wb = load_workbook(filename = fileName)\u000a            ws = wb.worksheets[0]\u000a            nCols = ws.get_highest_column()\u000a            nRows = ws.get_highest_row()\u000a                       \u000a            #get headers\u000a            fieldNames = [] \u000a            for colN in range(nCols):\u000a                #get filedName and chack valid\u000a                fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a                OK, msg = isValidVariableName(fieldName)\u000a                if not OK:\u000a                    #provide error message about incorrect header\u000a                    msg.replace('Variables','Parameters (column headers)') #tailor message to this usage\u000a                    raise ImportError, '%s: %s' %(fieldName, msg)\u000a                else: \u000a                    fieldNames.append(fieldName)\u000a                \u000a            #loop trialTypes\u000a            trialList = []\u000a            for rowN in range(nRows)[1:]:#not first row\u000a                thisTrial={}\u000a                for colN in range(nCols):\u000a                    fieldName = fieldNames[colN]\u000a                    val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                    #if it looks like a list, convert it\u000a                    if type(val)==str and val.startswith('[') and val.endswith(']'):\u000a                        exec('val=%s' %val)\u000a                    thisTrial[fieldName] = val\u000a                trialList.append(thisTrial)\u000a            \u000a        if returnFieldNames:\u000a            return (trialList,fieldNames)\u000a        else:\u000a            return trialList\u000a        \u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a    \u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a    \u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a    \u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"], \u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial conbinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler:\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a    \u000a    See ``demo_trialHandler.py``\u000a        \u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse\u000a    \u000a    """\u000a    def __init__(self,\u000a                 startVal, \u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None):\u000a        """\u000a        :Parameters:\u000a            \u000a            startVal:\u000a                The initial value for the staircase.\u000a            \u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a    \u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a            \u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a                \u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a                \u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a                \u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using \u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or \u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods. \u000a                \u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in \u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)     \u000a            \u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a            \u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a                \u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a            \u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a                \u000a        """\u000a        \u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a            \u000a            """        \u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a        \u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True          \u000a            \u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either \u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        \u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath==None or not os.path.isfile(originPath):\u000a            self.originPath = inspect.getouterframes(inspect.currentframe())[1][1]\u000a            log.debug("Using %s as origin file" %self.originPath)\u000a        else: self.originPath = originPath\u000a        self.origin = open(self.originPath).read().decode('utf8')\u000a        \u000a    def __iter__(self):\u000a        return self\u000a        \u000a    def addData(self, result):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        \u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.data.append(result)\u000a        \u000a        #increment the counter of correct scores\u000a        if result==1: \u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a                \u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a                \u000a        self.calculateNextIntensity()\u000a                                        \u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a        \u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially \u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                self._intensityDec()\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                    self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                self._intensityInc()\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a            \u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            #make it harder\u000a            self._intensityDec()\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a            \u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!            \u000a            #make it easier\u000a            self._intensityInc()\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a                \u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a            \u000a        \u000a        #add reversal info \u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a            #and test if we're done\u000a            if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a                len(self.intensities)>=self.nTrials:\u000a                    self.finished=True\u000a            #new step size if necessary\u000a            if self._variableStep and self.finished==False:\u000a                if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                    #we've gone beyond the list of step sizes so just use the last one\u000a                    self.stepSizeCurrent = self.stepSizes[-1]\u000a                else:\u000a                    self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a                \u000a                \u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.   \u000a        \u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a            \u000a            staircase = StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a           \u000a        or::\u000a            \u000a            staircase = StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a            \u000a        """\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1        \u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            raise StopIteration\u000a        \u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None: \u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a        \u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None: \u000a            self._nextIntensity = self.minVal\u000a        \u000a        \u000a    def saveAsText(self,fileName, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False,\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension \u000a                `.dlm` will be added if not included.\u000a            \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        \u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        \u000a        #create the file or print to stdout\u000a        if fileName=='stdout':\u000a            f = sys.stdout\u000a        elif fileName[-4:] in ['.dlm','.DLM', '.csv','.CSV']:\u000a            f= file(fileName,'w')\u000a        else:\u000a            if delim==',': f=file(fileName+'.csv','w')\u000a            else: f=file(fileName+'.dlm','w')\u000a            \u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', '\u005ct')\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a        \u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', '\u005ct')\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a        \u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', '\u005ct')\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a        \u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', '\u005ct')\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a        \u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a            \u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a            \u000a        f.write("\u005cn")        \u000a        if f != sys.stdout: \u000a            f.close()\u000a            log.info('saved data to %s' %f.name)\u000a        \u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have \u000a        one file for each participant and then multiple sheets for repeated sessions etc. \u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity \u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a        \u000a            sheetName: string\u000a                the name of the worksheet within the file \u000a                \u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a                \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a                \u000a        """\u000a        \u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl: \u000a            raise ImportError, 'openpyxl is required for saving files in Excel (xlsx) format, but was not found.'\u000a            return -1\u000a        \u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a        \u000a        if not fileName.endswith('.xlsx'): fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName): \u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                log.warning('Data file, %s, will be overwritten' %fileName)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a        \u000a        ew = ExcelWriter(workbook = wb)\u000a        \u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a        \u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a        \u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'; rowN+=1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        log.info('saved data to %s' %fileName)\u000a        \u000a    def saveAsPickle(self,fileName):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded if necess and further analyses carried out.\u000a        """\u000a        if self.thisTrialN<1:\u000a            log.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        log.info('saved data to %s' %f.name)\u000a        \u000a    def printAsText(self, stimOut=[], \u000a                    dataOut=('rt_mean','rt_std', 'acc_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText except that the output goes\u000a        to the screen instead of a file"""\u000a        self.saveAsText('stdout',  delim, matrixOnly)\u000a    \u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: StairHandler.nextTrial() will be deprecated\u000a        please use StairHandler.next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            log.warning("""DEPRECATION WARNING: StairHandler.nextTrial() will be deprecated\u000a        please use StairHandler.next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a        \u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm using python code from XXX.  f\u000a    Like StairHandler, it handles the selection of the next trial and report \u000a    current values etc. Calls to nextTrial() will fetch the next object given \u000a    to this handler, according to the method specified.\u000a\u000a    The staircase will terminate when *nTrials* or *XXX* has been exceeded.\u000a        \u000a    Measure threshold using a Weibull psychometric function. Currently, it is \u000a    not possible to use a different psychometric function.\u000a    \u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a    \u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a    \u000a    **Example**::\u000a    \u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # add response\u000a            staircase.addData(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a        \u000a    """\u000a    def __init__(self,\u000a                 startVal, \u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a        \u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a        \u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function. \u000a        \u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a                \u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a            \u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e., \u000a                the midpoint of the table) yields pThreshold..\u000a            \u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a            \u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a            \u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a            \u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels \u000a                into decibels or log units and will move along the psychometric function with these values.\u000a            \u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a            \u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using \u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or \u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a            \u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a            \u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a            \u000a        """\u000a        \u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method, \u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a        \u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a                \u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a        \u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a        \u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a    \u000a    def addData(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        Also update the intensity\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        self.calculateNextIntensity()\u000a    \u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError, "length of intensities and results input must be the same"\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addData(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    \u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None: \u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a    \u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        return scaled_intensity\u000a    \u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        return intensity\u000a    \u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode())\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a    \u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a    \u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a    \u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest, \u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a    \u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a        \u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1        \u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            raise StopIteration\u000a    \u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass MultiStairHandler:\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or QUEST)\u000a        \u000a        \u000a        :params:\u000a        \u000a            stairType: 'simple' or 'quest'\u000a                Use a `~psychopy.data.StairHandler`_ or `~psychopy.data.QuestHandler`_\u000a                \u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than \u000a                that (so you can't have 3 repeats of the same staircase in a row \u000a                unless it's the only one still running)\u000a                \u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importTrialTypes`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a                \u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't \u000a                also met its minimal reversals. See `~psychopy.data.StairHandler`\u000a                \u000a        Example usage::\u000a        \u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = MultiStairHandler(conditions=conditions, trials=50)\u000a            \u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a                \u000a                #do something with thisIntensity and thisOri\u000a                \u000a                stairs.addData(correctIncorrect)#this is ESSENTIAL\u000a                \u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a            \u000a        """\u000a        \u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            raise TypeError('conditions parameter to MultiStairHandler should be a list, not a %s' %type(conditions))\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            raise TypeError('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest']:\u000a            if 'startVal' not in params: \u000a                raise ValueError('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params: \u000a                raise ValueError('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type=='quest': \u000a                raise ValueError("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            raise ValueError("MultiStairHandler `stairType` should be 'simple' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials, \u000a                'nUp':1, 'nDown':3, 'extraInfo':None, \u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type=='quest':\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None, \u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01, \u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None, \u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a        \u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter \u000a                if paramName in condition.keys(): val=condition[paramName]\u000a                else: val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals, \u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown, \u000a                    extraInfo=extraInfo, \u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type=='quest':\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'], \u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval, \u000a                    method=method, stepType=stepType, beta=beta, delta=delta, \u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo, \u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        \u000a        This can be handled with code such as::\u000a            \u000a            staircase = MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a           \u000a        or::\u000a            \u000a            staircase = MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a            \u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a                if self.method=='random': numpy.random.shuffle(self.thisPassRemaining)\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #return value\u000a        if self.finished==False:\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a    \u000a    def addData(self, result):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        \u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addData(result)\u000a        try:\u000a            self.currentStaircase.next()\u000a        except:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        self.totalTrials+=1\u000a    def saveAsPickle(self, fileName):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a        \u000a        This can be reloaded later and further analyses carried out.\u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        f = open(fileName+'.psydat', "wb")\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        log.info('saved data to %s' %f.name)\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing \u000a        in most spreadsheet packages. This format is compatible with \u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a        \u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of \u000a        conditions during initialisation of the Handler.\u000a        \u000a        The file extension `.xlsx` will be added if not given already.\u000a        \u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity \u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a        \u000a        :Parameters:\u000a        \u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a                \u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a                \u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a                \u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN==0: append=appendFile\u000a            else: append=True\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(fileName=fileName, sheetName=label, \u000a                matrixOnly=False, appendFile=append)\u000a    def saveAsText(self,fileName, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write out text files with the data. \u000a        \u000a        For MultiStairHandler this will output one file for each staircase \u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler). \u000a        \u000a        :Parameters:\u000a        \u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension \u000a                `.dlm` will be added if not included.\u000a            \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        if self.totalTrials<1:\u000a            log.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(fileName=thisFileName, delim=delim, \u000a                matrixOnly=matrixOnly)\u000a    def printAsText(self, \u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream \u000a        \u000a        :Parameters:\u000a        \u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a                \u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs=len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN<(nStairs-1): thisMatrixOnly=True #never print info for first files\u000a            else: thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" %label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim, \u000a                matrixOnly=thisMatrixOnly)\u000a        \u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a    \u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a    \u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a    \u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape: self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a            \u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes: \u000a                self.addDataType(thisType)\u000a    \u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape: shape = self.dataShape\u000a        if type(names) != str:\u000a            #recursively call this function until we have a string\u000a            for thisName in names: self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not self.has_key(thisType):\u000a            self.addDataType(thisType)\u000a        if position==None: \u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(self.trials.thisRepN)\u000a            \u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            log.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=misc.extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    \u000a    def __init__(self, fnName, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.fnName = fnName\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.params = guess\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        \u000a        if fnName[-4:] in ['2AFC', 'TAFC']:\u000a            self.expectedMin = 0.5\u000a        elif fnName[-2:] =='YN':\u000a            self.expectedMin=0.0\u000a        else:\u000a            self.expectedMin=expectedMin\u000a            \u000a        #do the calculations:\u000a        self._doFit()\u000a        \u000a    def _doFit(self):\u000a        #get some useful variables to help choose starting fit vals\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        if self.fnName in ['weibullTAFC','weibullYN']:\u000a            if self.params==None: guess=[xMean, xRange/5.0]\u000a            else: guess= numpy.asarray(self.params,'d')\u000a        elif self.fnName in ['cumNorm','erf']:\u000a            if self.params==None: guess=[xMean, xRange/5.0]#c50, xScale (slope)\u000a            else: guess= numpy.asarray(self.params,'d')\u000a        elif self.fnName in ['logisticTAFC','logistYN', 'logistic']:\u000a            if self.params==None: guess=[xMin, 5.0/xRange]#x0, xRate\u000a            else: guess= numpy.asarray(self.params,'d')  \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']: \u000a            if self.params==None: guess=[xMean, 2.0]#x50, expon\u000a            else: guess= numpy.asarray(self.params,'d')  \u000a        \u000a        self.params = optimize.fmin_cg(self._getErr, guess, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a        \u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a\u000a    def eval(self, xx=None, params=None):\u000a        if xx==None: xx=self.xx\u000a        if params==None: params=self.params\u000a        if self.fnName in ['weibullTAFC', 'weibull2AFC']:\u000a            alpha = params[0]; \u000a            if alpha<=0: alpha=0.001\u000a            beta = params[1]\u000a            xx = numpy.asarray(xx)\u000a            yy =  1.0 - 0.5*numpy.exp( - (xx/alpha)**beta ) \u000a        elif self.fnName == 'weibullYN':\u000a            alpha = params[0]; \u000a            if alpha<=0: alpha=0.001\u000a            beta = params[1]\u000a            xx = numpy.asarray(xx)\u000a            yy =  1.0 - numpy.exp( - (xx/alpha)**beta )         \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']:\u000a            c50 = params[0]\u000a            if c50<=0: c50=0.001\u000a            n = params[1]\u000a            if n<=0: n=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = rMax*(xx**n/(xx**n+c50**n))\u000a        elif self.fnName in [ 'erf', 'cumNorm']:\u000a            xShift = params[0]\u000a            xScale = params[1]\u000a            if xScale<=0: xScale=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = special.erf(xx*xScale - xShift)*0.5+0.5#numpy.special.erf() goes from -1:1\u000a        elif self.fnName in [ 'logisticYN', 'logistYN']:\u000a            x0 = params[0]\u000a            xRate = params[1]\u000a            if xRate<=0: xRate=0.001\u000a            xx = numpy.asarray(xx)\u000a            yy = 1.0/(1+(1.0/x0-1)*numpy.exp(-xRate*xx))\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        """Returns fitted xx for any given yy value(s).\u000a        \u000a        If params is specified this will override the current model params.\u000a        """\u000a        yy = numpy.asarray(yy)\u000a        if params==None: params=self.params\u000a        if self.fnName== 'weibullTAFC':\u000a            alpha = params[0]\u000a            beta = params[1]            \u000a            xx = alpha * (-numpy.log(2.0 * (1.0-yy))) **(1.0/beta)\u000a        elif self.fnName== 'weibullYN':\u000a            alpha = params[0]\u000a            beta = params[1]            \u000a            xx = alpha * (-numpy.log(1.0-yy))**(1.0/beta)\u000a        elif self.fnName in [ 'erf', 'cumNorm']:\u000a            xShift = params[0]\u000a            xScale = params[1]\u000a            xx = (special.erfinv(yy*2.0-1.0)+xShift)/xScale\u000a        elif self.fnName in [ 'logisticYN', 'logistYN']:\u000a            x0 = params[0]\u000a            xRate = params[1]\u000a            xx = -numpy.log( (1/yy-1)/(1/x0-1) )/xRate      \u000a        elif self.fnName in ['nakaRush', 'nakaRushton', 'NR']:\u000a            c50 = params[0]\u000a            n = params[1]\u000a            xx = c50/(1/yy-1)\u000a        return xx\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a    \u000a    You must overide the eval and inverse methods and a good idea to overide the _initialGuess\u000a    method aswell.\u000a    """\u000a    \u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #initialise parameters\u000a        if guess==None:\u000a            self.params = self._initialGuess()\u000a        else:\u000a            self.params = guess\u000a                \u000a        #do the calculations:\u000a        self._doFit()\u000a        \u000a    def _doFit(self):\u000a        #get some useful variables to help choose starting fit vals     \u000a#        self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    \u000a    def _initialGuess(self):\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        guess=[xMean, xRange/5.0]\u000a        return guess\u000a\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a\u000a    def eval(self, xx=None, params=None):\u000a        """Returns fitted yy for any given xx value(s).\u000a        Uses the original xx values (from which fit was calculated)\u000a        if none given.\u000a        \u000a        If params is specified this will override the current model params."""\u000a        yy=xx\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        """Returns fitted xx for any given yy value(s).\u000a        \u000a        If params is specified this will override the current model params.\u000a        """\u000a        #define the inverse for your function here\u000a        xx=yy\u000a        return xx\u000a\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a    \u000a    	y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a    \u000a    and with inverse::\u000a    \u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a        \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[alpha, beta]``)"""\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        alpha = params[0]; \u000a        if alpha<=0: alpha=0.001\u000a        beta = params[1]\u000a        xx = numpy.asarray(xx)\u000a        yy =  self.expectedMin + (1.0-self.expectedMin)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        alpha = params[0]\u000a        beta = params[1]            \u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-self.expectedMin))) **(1.0/beta)\u000a        return xx\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a    \u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a    \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a    \u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.display=display\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #initialise parameters\u000a        if guess==None:\u000a            self.params = self._initialGuess()\u000a        else:\u000a            self.params = guess\u000a                \u000a        #do the calculations:\u000a        self._doFit()\u000a    def _initialGuess(self):\u000a        xMin = min(self.xx); xMax = max(self.xx)\u000a        xRange=xMax-xMin; xMean= (xMax+xMin)/2.0\u000a        guess=[xMean, 2.0, min(self.yy), max(self.yy)-min(self.yy)]\u000a        return guess \u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        c50 = params[0]\u000a        n = params[1]\u000a        rMin = params[2]\u000a        rMax = params[3]\u000a        #all params should be >0\u000a        if c50<=0: c50=0.001\u000a        if n<=0: n=0.001\u000a        if rMax<=0: n=0.001\u000a        if rMin<=0: n=0.001\u000a        \u000a        xx = numpy.asarray(xx)\u000a        yy = rMin + (rMax-rMin)*(xx**n/(xx**n+c50**n))\u000a        #yy = (xx**n/(xx**n+c50**n))\u000a        return yy\u000a    \u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        yy=numpy.asarray(yy)\u000a        c50 = params[0]\u000a        n = params[1]\u000a        rMin = params[2]\u000a        rMax = params[3]\u000a        \u000a        yScaled = (yy-rMin)/(rMax-rMin) #remove baseline and scale\u000a        xx = (yScaled*c50**n/(1-yScaled))**(1/n)\u000a        return xx\u000a    \u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN) \u000a    of the form::\u000a    \u000a    	y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a    \u000a    and with inverse::\u000a    \u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a    \u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with \u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params`` \u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        PSE = params[0]\u000a        JND = params[1]\u000a        chance = self.expectedMin\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        PSE = params[0]\u000a        JND = params[1]\u000a        chance = self.expectedMin\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-chance)/(yy-chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf) \u000a    of the form::\u000a    \u000a    	y = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)\u000a    \u000a    and with inverse::\u000a    \u000a        x = (erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale\u000a        \u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with \u000a    fit.inverse(y) or retrieve the parameters from fit.params \u000a    (a list with [xShift, xScale])\u000a    """\u000a    def eval(self, xx=None, params=None):\u000a        if params==None:  params=self.params #so the user can set params for this particular eval\u000a        xShift = params[0]\u000a        xScale = params[1]\u000a        chance = self.expectedMin        \u000a        if xScale<=0: xScale=0.001\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)*(special.erf(xx*xScale - xShift)/2.0+0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        if params==None: params=self.params #so the user can set params for this particular inv\u000a        xShift = params[0]\u000a        xScale = params[1]\u000a        chance = self.expectedMin\u000a        xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erf() goes from -1:1\u000a        return xx\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a    \u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a    \u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a    \u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a            \u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a    \u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure\u000a    \u000a    usage::\u000a    \u000a    	[intensity, meanCorrect, n] = functionFromStaircase(intensities, responses, bins)\u000a    \u000a    where:\u000a            intensities \u000a                are a list of intensities to be binned\u000a                \u000a            responses \u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a                \u000a            bins \u000a                can be an integer (giving that number of bins) or 'unique' (where each bin is made from ALL data for exactly one intensity value)\u000a\u000a            intensity \u000a                is the center of an intensity bin\u000a                \u000a            meanCorrect \u000a                is mean % correct in that bin\u000a                \u000a            n \u000a                is number of responses contributing to that mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a    \u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a    \u000a    binnedResp=[]; binnedInten=[]; nPoints = []\u000a    if bins=='unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            \u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a        \u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    Apr_19_1531 for 19th April 3.31pm.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    """\u000a    return time.strftime(format, time.localtime())\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a    \u000a    Usage:: \u000a        \u000a        OK, msg = isValidVariableName(name)\u000a        \u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    """\u000a    punctuation = " -[]()+*@!$%^&/\u005c{}~.,?'|:;"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name)==unicode:\u000a            raise AttributeError, "name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name))\u000a        else:\u000a            raise AttributeError, "name %s (type %s) could not be converted to a string" % (name, type(name))\u000a            \u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    for chr in punctuation:\u000a        if chr in name: return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a    \u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a    \u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a    \u000a
p67
sg16
I3
sg17
(lp68
F0.7924465962305568
aF1.2559432157547903
aF0.7924465962305568
aF19.905358527674874
asg19
I4
sg20
I1
sg21
F0.5
sg3
F12.559432157547906
sg22
I01
sg23
g24
sg25
Nsg26
I4
sg27
I0
sg28
Nsg29
Nsg30
I01
sg31
g32
sg33
(lp69
I0
aI1
aI1
aI1
aI0
aI0
aI1
aI1
aI1
aI0
aI1
aI0
aI0
aI1
aI0
aI0
aI0
aI1
aI0
aI1
aI1
aI1
asg35
(dp70
g37
F0.5
sg38
Vmedium
p71
sg40
F0.10000000000000001
sg41
I10
ssg42
(lp72
I0
aI7
aI8
aI20
asg44
g45
sg46
Nsg47
g48
sg49
I00
sg50
(lp73
F0.7924465962305568
aF0.5
aF0.5
aF0.5
aF0.7924465962305568
aF1.2559432157547903
aF1.2559432157547903
aF1.2559432157547903
aF0.7924465962305568
aF1.2559432157547903
aF1.2559432157547903
aF1.9905358527674868
aF3.1547867224009671
aF3.1547867224009671
aF5.0000000000000018
aF7.9244659623055709
aF12.559432157547906
aF12.559432157547906
aF19.905358527674874
aF19.905358527674874
aF19.905358527674874
asg52
I10
sg53
I20
sbag12
asg52
I10
sS'conditions'
p74
(lp75
g61
ag70
ag36
asg23
S'random'
p76
sb.